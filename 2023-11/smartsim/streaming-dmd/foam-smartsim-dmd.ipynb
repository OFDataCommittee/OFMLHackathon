{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92a3898a-9fed-41eb-9463-2c9d559f8c0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SmartRedis Library@17-49-21:WARNING: Environment variable SR_LOG_FILE is not set. Defaulting to stdout\n",
      "SmartRedis Library@17-49-21:WARNING: Environment variable SR_LOG_LEVEL is not set. Defaulting to INFO\n",
      "17:49:21 argo SmartSim[40480] INFO Stopping model orchestrator_0 with job name orchestrator_0-CWTL1TIFBK5D\n",
      "17:49:23 argo SmartSim[40480] INFO foamSmartSimDmd(40576): Completed\n"
     ]
    }
   ],
   "source": [
    "from smartsim import Experiment\n",
    "from smartredis import Client\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import io\n",
    "\n",
    "def sort_tensors_by_names(tensors, tensor_names):\n",
    "    # Pair each tensor with its name and sort by the name\n",
    "    pairs = sorted(zip(tensor_names, tensors))\n",
    "\n",
    "    # Extract the sorted tensors\n",
    "    tensor_names_sorted, tensors_sorted = zip(*pairs)\n",
    "\n",
    "    # Convert back to list if needed\n",
    "    tensor_names_sorted = list(tensor_names_sorted)\n",
    "    tensors_sorted = list(tensors_sorted)\n",
    "\n",
    "    return tensors_sorted, tensor_names_sorted\n",
    "\n",
    "def set_model_in_database(model, client, key, input_array, device='CPU'):\n",
    "    \"\"\"\n",
    "    jit-trace and set the model in the database with a specified key\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare tracing for either GPU or CPU\n",
    "    if device.lower() == 'gpu':\n",
    "        if not torch.cuda.is_avaialable():\n",
    "            raise Exception(\"CUDA is not available, cannot trace the model for execution on GPUs\")\n",
    "    device_name = \"cuda\" if device.lower()==\"gpu\" else \"cpu\"\n",
    "    torch_device = torch.device(device_name)\n",
    "\n",
    "    # Create an example input tensor used for the tracing, adding a singleton dimension for the 'batch' dimension\n",
    "    example_input = np.expand_dims(input_array, axis=0)\n",
    "    ## What type of float is it in OpenFOAM?\n",
    "    example_input = torch.from_numpy(example_input).double().to(torch_device)\n",
    "\n",
    "    # Move the model onto the correct device (CPU or GPU)\n",
    "    model.to(torch_device)\n",
    "    model.eval() # Occasionally necessary to \n",
    "\n",
    "    # Trace the model\n",
    "    traced_model = torch.jit.trace(model, example_input)\n",
    "    \n",
    "    # Serialize the traced moel\n",
    "    buffer = io.BytesIO()\n",
    "    torch.save(traced_model, buffer)\n",
    "\n",
    "    client.set_model(key, traced_model, \"TORCH\", device)\n",
    "\n",
    "# Set up the execution of the foamSmartSimMapField application \n",
    "# as a SmartSim Experiment. \n",
    "exp = Experiment(\"foam-smartsim-dmd\", launcher=\"local\")\n",
    "\n",
    "db = exp.create_database(port=8000,       # database port\n",
    "                         interface=\"lo\")  # network interface to use\n",
    "exp.start(db)\n",
    "\n",
    "# Connect the python client to the smartredis database\n",
    "client = Client(address=db.get_address()[0], cluster=False)\n",
    "\n",
    "# Serial execution run settings for foamSmartSimDmd\n",
    "num_mpi_ranks = 1\n",
    "run_settings_serial = exp.create_run_settings(exe=\"foamSmartSimDmd\", \n",
    "                                              exe_args=\"-case cavity -fieldName p\")\n",
    "\n",
    "# MPI parallel run settings for foamSmartSimMapFields - run_command can be \"slurm\" on a cluster.\n",
    "n_mpi_ranks = 4\n",
    "run_settings_parallel = exp.create_run_settings(exe=\"foamSmartSimDmd\", \n",
    "                                                exe_args=\"-case cavity -fieldName p -parallel\", \n",
    "                                                run_command=\"mpirun\", \n",
    "                                                run_args={\"np\": f\"{num_mpi_ranks}\"})\n",
    "\n",
    "openfoam_dmd_model = exp.create_model(name=\"foamSmartSimDmd\", run_settings=run_settings_serial)\n",
    "\n",
    "try:\n",
    "     torch.set_default_dtype(torch.float64)\n",
    "    \n",
    "     # Run foamSmartSimMapFields and do not block\n",
    "     exp.start(openfoam_dmd_model, block=False)\n",
    "\n",
    "#     # Poll the cell centers in smartredis\n",
    "#     input_cell_centers_updated = client.poll_list_length(\"inputCentersDatasetList\", \n",
    "#                                                           num_mpi_ranks, 10, 1000);\n",
    "#     if (not input_cell_centers_updated):     \n",
    "#         raise ValueError(\"Input cell centers dataset list not available in smartredis.\")\n",
    "#     else:\n",
    "#         print (\"Input cell centers datasets available.\")\n",
    "\n",
    "#     # Poll the input field in smartredis \n",
    "#     input_field_updated = client.poll_list_length(\"inputFieldDatasetList\", \n",
    "#                                                   num_mpi_ranks, 10, 1000);\n",
    "#     if (not input_field_updated):     \n",
    "#         raise ValueError(\"Input field dataset list not available in smartredis.\")\n",
    "#     else:\n",
    "#         print (\"Input field datasets available.\")\n",
    "\n",
    "#     # - Get the datasets\n",
    "#     input_centers_datasets = client.get_datasets_from_list(\"inputCentersDatasetList\");  \n",
    "#     input_field_datasets = client.get_datasets_from_list(\"inputFieldDatasetList\");\n",
    "\n",
    "#     # - Agglomerate all input data tensors from smartredis for the ML model training\n",
    "#     input_centers = []\n",
    "#     input_centers_names = []\n",
    "#     input_field = []\n",
    "#     input_field_names = []\n",
    "\n",
    "#     # Loop over all datasets that agglomerate input cell center tensors and input field tensors per MPI rank\n",
    "#     # and append the tensors to the global list of tensors along with their names. Sort the tensors w.r.t.\n",
    "#     # their names, i.e. w.r.t MPI rank to make sure that a cell center from an MPI rank corresponds to the \n",
    "#     # right field data from the same MPI rank.\n",
    "#     for input_centers_dset, input_field_dset in zip(input_centers_datasets, input_field_datasets):\n",
    "#         input_centers_tensor_names = input_centers_dset.get_tensor_names()\n",
    "#         input_field_tensor_names = input_field_dset.get_tensor_names()\n",
    "#         for input_centers_name,input_field_name in zip(input_centers_tensor_names,input_field_tensor_names):\n",
    "            \n",
    "#             input_centers.append(input_centers_dset.get_tensor(input_centers_name))\n",
    "#             input_centers_names.append(input_centers_name)\n",
    "            \n",
    "#             input_field.append(input_field_dset.get_tensor(input_field_name))\n",
    "#             input_field_names.append(input_field_name)\n",
    "            \n",
    "#     input_centers, input_center_names = sort_tensors_by_names(input_centers, input_centers_names)\n",
    "#     input_field, input_field_names = sort_tensors_by_names(input_field, input_field_names)\n",
    "    \n",
    "#     # Flatten the training data\n",
    "#     input_field = torch.from_numpy(np.vstack(input_field)).double()\n",
    "#     input_centers = torch.from_numpy(np.vstack(input_centers)).double()\n",
    "\n",
    "#     # TODO(TM): hardcoded 2D dimensions, remove in a 3D simulation, adapt if 2D solution dimensions differ.'\n",
    "#     # FIXME(TM): use polyMesh::solutionD\n",
    "#     field_rank_found = client.poll_tensor(\"input_field_rank\", 10, 1000)\n",
    "#     if (not field_rank_found):     \n",
    "#             raise ValueError(\"Input field rank not available in smartredis.\")\n",
    "#     input_field_rank = client.get_tensor(\"input_field_rank\")\n",
    "\n",
    "#     if (input_field_rank[0] > 0):\n",
    "#         input_field = input_field[:, :2]\n",
    "#     input_centers = input_centers[:, :2]\n",
    "\n",
    "#     # Train an ML model M(cell_center, theta), M: cell_center -> input_field\n",
    "#     # Split training and validation data\n",
    "#     field_train, field_val, centers_train, centers_val = train_test_split(input_field, input_centers, \n",
    "#                                                                           test_size=0.2, random_state=42)\n",
    "\n",
    "#     # Fit the scaler on the training data\n",
    "#     target_scaler = MinMaxScaler().fit(field_train.numpy()) \n",
    "    \n",
    "#     # Transform the training and validation data\n",
    "#     field_train = torch.from_numpy(target_scaler.transform(field_train.numpy())).double()\n",
    "#     field_val = torch.from_numpy(target_scaler.transform(field_val.numpy())).double()\n",
    "\n",
    "#     # Initialize the model\n",
    "#     # TODO(TM): ML model should decide on the output rank based on the metadata sent by OpenFOAM.\n",
    "#     model = MLP(num_layers=4, layer_width=40, input_size=2, output_size=1, activation_fn=nn.Tanh)\n",
    "#     #model = MLP(num_layers=4, layer_width=40, input_size=2, output_size=1, activation_fn=torch.nn.Tanh())\n",
    "\n",
    "\n",
    "#     # PYTORCH Training Loop\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "#     loss_func = nn.MSELoss()create_database\n",
    "#     epochs = 50\n",
    "#     mean_mag_displ = torch.mean(torch.norm(field_train, dim=1))\n",
    "#     for epoch in range(epochs):\n",
    "#         # Zero the gradients\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # Forward pass on the training data\n",
    "#         field_pred = model(centers_train)\n",
    "\n",
    "#         # Compute loss on the training data\n",
    "#         loss_train = loss_func(field_pred, field_train)\n",
    "\n",
    "#         # Backward pass and optimization\n",
    "#         loss_train.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # Forward pass on the validation data, with torch.no_grad() for efficiency\n",
    "#         with torch.no_grad():\n",
    "#             field_pred_val = model(centers_val)\n",
    "#             loss_val = loss_func(field_pred_val, field_val)\n",
    "#             rmse_loss_val = torch.sqrt(loss_val)\n",
    "#             print (f'Validation loss RMSE : {rmse_loss_val}')\n",
    "#             print(f'Epoch {epoch+1}/{epochs}, Training Loss: {loss_train.item()}, Validation Loss: {loss_val.item()}')\n",
    "\n",
    "#     # Visualize the input field\n",
    "#     vis_centers = list(zip(*input_centers))\n",
    "#     if (input_field_rank[0] == 0):\n",
    "#         # TODO(TM): have OpenFOAM store a field name into a metadata dataset. \n",
    "#         #           Get the input field name and use it in a title of the plot.\n",
    "#         plt.title(\"Input fimapfieldseld\")\n",
    "#         plt.scatter(vis_centers[0], vis_centers[1], c=input_field, cmap='viridis')\n",
    "#         plt.colorbar()\n",
    "        \n",
    "#     # Visualize the ML approximation\n",
    "#     plt.figure()\n",
    "#     field_pred = model(input_centers)\n",
    "#     field_pred_np = torch.from_numpy(target_scaler.inverse_transform(field_pred.detach().numpy())).double()\n",
    "#     if (input_field_rank[0] == 0):\n",
    "#         # TODO(TM): have OpenFOAM store a field name into a metadata dataset. \n",
    "#         #           Get the input field name and use it in a title of the plot.\n",
    "#         plt.title(\"Approximated field\")\n",
    "#         plt.scatter(vis_centers[0], vis_centers[1], c=field_pred_np, cmap='viridis')\n",
    "#         plt.colorbar()\n",
    "\n",
    "#     # Visualize the approximation error\n",
    "#     approx_error = torch.abs(input_field - field_pred_np)\n",
    "#     plt.figure()\n",
    "#     if (input_field_rank[0] == 0):\n",
    "#         #TODO(TM): have OpenFOAM store a field name into a metadata dataset. \n",
    "#         #          Get the input field name and use it in a title of the plot.\n",
    "#         plt.title(\"Approximation error absolute\")\n",
    "#         plt.scatter(vis_centers[0], vis_centers[1], c=approx_error, cmap='viridis')\n",
    "#         plt.colorbar()\n",
    "\n",
    "#     # Save traced model in the database for use by other SmartRedis clients\n",
    "#     set_model_in_database(model, client, \"map_fields_model\", input_centers, device='CPU')\n",
    "    \n",
    "#     # Perform forward inference of the model in smartredis using cell_centers as input and store output. \n",
    "#     # Andrew: I think you want to do this on the OpenFOAM side for the data that\n",
    "#     # is on each OpenFOAM subdomain, but to do it in\n",
    "#     # Python\n",
    "#     #client.put_tensor(\"ml_input\", input_centers)\n",
    "#     #client.run_model(\"map_fields_model\", [\"ml_input\"], [\"ml_output\"])\n",
    "#     #prediction = client.get_tensor(\"ml_output\")\n",
    "\n",
    "#     # Save the key in smartredis that forward pass has completed.\n",
    "#     # Andrew: The existence of \"ml_output\" is probably sufficient. Maybe just\n",
    "#     # delete the key on the OpenFOAM side once all the ranks have read the output. \n",
    "#     # Can also do the same for the model\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Caught an exception: \", str(e))\n",
    "    \n",
    "finally:\n",
    "    exp.stop(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280c909b-463d-425e-bc78-70fbc1ae8be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a215654-7f91-48d6-9fd8-690213c647e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
